{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import plotly.graph_objects as go\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "chart_studio.tools.set_config_file(world_readable=True,\n",
    "                             sharing='public')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stonks = pd.read_csv(\"stonks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>2000-03-29</td>\n",
       "      <td>151.5625</td>\n",
       "      <td>152.4843</td>\n",
       "      <td>149.6562</td>\n",
       "      <td>151.2187</td>\n",
       "      <td>6747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>150.1562</td>\n",
       "      <td>151.9218</td>\n",
       "      <td>147.1250</td>\n",
       "      <td>148.6875</td>\n",
       "      <td>9491900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>149.6250</td>\n",
       "      <td>152.3125</td>\n",
       "      <td>148.4375</td>\n",
       "      <td>150.3750</td>\n",
       "      <td>9249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>150.1250</td>\n",
       "      <td>151.2500</td>\n",
       "      <td>148.6875</td>\n",
       "      <td>151.2500</td>\n",
       "      <td>8508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>2000-04-04</td>\n",
       "      <td>151.7500</td>\n",
       "      <td>153.0000</td>\n",
       "      <td>141.3906</td>\n",
       "      <td>150.1250</td>\n",
       "      <td>19585500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close    volume\n",
       "5032  2000-03-29  151.5625  152.4843  149.6562  151.2187   6747500\n",
       "5031  2000-03-30  150.1562  151.9218  147.1250  148.6875   9491900\n",
       "5030  2000-03-31  149.6250  152.3125  148.4375  150.3750   9249100\n",
       "5029  2000-04-03  150.1250  151.2500  148.6875  151.2500   8508200\n",
       "5028  2000-04-04  151.7500  153.0000  141.3906  150.1250  19585500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stonks = stonks.iloc[::-1]\n",
    "stonks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151.2187],\n",
       "       [148.6875],\n",
       "       [150.375 ],\n",
       "       ...,\n",
       "       [185.49  ],\n",
       "       [187.01  ],\n",
       "       [188.25  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_percent = 0.7\n",
    "val_percent = 0.1\n",
    "\n",
    "close_data = stonks[[\"open\", \"high\", \"low\", \"close\"]].values.reshape((-1,4))\n",
    "\n",
    "split = int(split_percent*len(close_data))\n",
    "val = int((val_percent + split_percent) * len(close_data))\n",
    "close_train = close_data[:split]\n",
    "close_val = close_data[split:val]\n",
    "close_test = close_data[val:]\n",
    "\n",
    "date_train = stonks.timestamp[:split]\n",
    "date_val = stonks.timestamp[split:val]\n",
    "date_test = stonks.timestamp[val:]\n",
    "\n",
    "close_train[0:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 176 steps, validate for 49 steps\n",
      "Epoch 1/64\n",
      "176/176 [==============================] - 2s 13ms/step - loss: 607.6630 - accuracy: 0.3709 - cosine_proximity: 0.9895 - val_loss: 65.5553 - val_accuracy: 0.0082 - val_cosine_proximity: 0.9994\n",
      "Epoch 2/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 22.9906 - accuracy: 0.3392 - cosine_proximity: 0.9998 - val_loss: 37.8637 - val_accuracy: 0.5840 - val_cosine_proximity: 0.9998\n",
      "Epoch 3/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 20.2733 - accuracy: 0.4036 - cosine_proximity: 0.9998 - val_loss: 56.5909 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9995\n",
      "Epoch 4/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 25.4811 - accuracy: 0.3575 - cosine_proximity: 0.9998 - val_loss: 42.1358 - val_accuracy: 0.0082 - val_cosine_proximity: 0.9998\n",
      "Epoch 5/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 18.3298 - accuracy: 0.4330 - cosine_proximity: 0.9999 - val_loss: 29.9210 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9999\n",
      "Epoch 6/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 20.9714 - accuracy: 0.4359 - cosine_proximity: 0.9999 - val_loss: 150.8170 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9990\n",
      "Epoch 7/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 26.5211 - accuracy: 0.3726 - cosine_proximity: 0.9997 - val_loss: 21.4993 - val_accuracy: 0.0020 - val_cosine_proximity: 1.0000\n",
      "Epoch 8/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 18.3648 - accuracy: 0.4749 - cosine_proximity: 0.9999 - val_loss: 22.5083 - val_accuracy: 0.0082 - val_cosine_proximity: 0.9999\n",
      "Epoch 9/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 21.3788 - accuracy: 0.4387 - cosine_proximity: 0.9999 - val_loss: 33.0415 - val_accuracy: 0.0041 - val_cosine_proximity: 0.9998\n",
      "Epoch 10/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 19.6503 - accuracy: 0.3925 - cosine_proximity: 0.9999 - val_loss: 40.1081 - val_accuracy: 0.9816 - val_cosine_proximity: 1.0000\n",
      "Epoch 11/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 14.6343 - accuracy: 0.5915 - cosine_proximity: 1.0000 - val_loss: 20.9655 - val_accuracy: 0.0082 - val_cosine_proximity: 1.0000\n",
      "Epoch 12/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 18.3205 - accuracy: 0.5140 - cosine_proximity: 0.9999 - val_loss: 55.2782 - val_accuracy: 0.9898 - val_cosine_proximity: 0.9999\n",
      "Epoch 13/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 20.7761 - accuracy: 0.5123 - cosine_proximity: 0.9999 - val_loss: 44.6111 - val_accuracy: 0.7828 - val_cosine_proximity: 1.0000\n",
      "Epoch 14/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 16.9678 - accuracy: 0.5647 - cosine_proximity: 0.9999 - val_loss: 75.2895 - val_accuracy: 0.1352 - val_cosine_proximity: 0.9998\n",
      "Epoch 15/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 15.4292 - accuracy: 0.5217 - cosine_proximity: 0.9999 - val_loss: 41.9766 - val_accuracy: 0.0082 - val_cosine_proximity: 0.9999\n",
      "Epoch 16/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 13.8305 - accuracy: 0.5339 - cosine_proximity: 0.9999 - val_loss: 57.4256 - val_accuracy: 0.9918 - val_cosine_proximity: 0.9999\n",
      "Epoch 17/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 16.1419 - accuracy: 0.5288 - cosine_proximity: 0.9999 - val_loss: 40.1294 - val_accuracy: 0.9918 - val_cosine_proximity: 1.0000\n",
      "Epoch 18/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 12.8756 - accuracy: 0.5724 - cosine_proximity: 0.9999 - val_loss: 22.2814 - val_accuracy: 0.9918 - val_cosine_proximity: 1.0000\n",
      "Epoch 19/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 15.5394 - accuracy: 0.5154 - cosine_proximity: 0.9999 - val_loss: 22.7155 - val_accuracy: 0.0451 - val_cosine_proximity: 1.0000\n",
      "Epoch 20/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 13.2112 - accuracy: 0.5265 - cosine_proximity: 0.9999 - val_loss: 141.3266 - val_accuracy: 0.0164 - val_cosine_proximity: 1.0000\n",
      "Epoch 21/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 19.5944 - accuracy: 0.4418 - cosine_proximity: 0.9999 - val_loss: 32.7405 - val_accuracy: 0.5943 - val_cosine_proximity: 0.9999\n",
      "Epoch 22/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 15.2780 - accuracy: 0.5154 - cosine_proximity: 0.9999 - val_loss: 17.9246 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 1.0000\n",
      "Epoch 23/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 11.2188 - accuracy: 0.6006 - cosine_proximity: 1.0000 - val_loss: 18.6756 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9999\n",
      "Epoch 24/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 11.6963 - accuracy: 0.5733 - cosine_proximity: 0.9999 - val_loss: 17.6365 - val_accuracy: 0.4959 - val_cosine_proximity: 1.0000\n",
      "Epoch 25/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 13.0148 - accuracy: 0.5750 - cosine_proximity: 1.0000 - val_loss: 17.2614 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9999\n",
      "Epoch 26/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 13.7543 - accuracy: 0.6043 - cosine_proximity: 1.0000 - val_loss: 23.3431 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 1.0000\n",
      "Epoch 27/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 13.5843 - accuracy: 0.6317 - cosine_proximity: 1.0000 - val_loss: 21.6243 - val_accuracy: 0.9672 - val_cosine_proximity: 1.0000\n",
      "Epoch 28/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 13.6269 - accuracy: 0.5060 - cosine_proximity: 0.9999 - val_loss: 12.5653 - val_accuracy: 0.0676 - val_cosine_proximity: 1.0000\n",
      "Epoch 29/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 13.1898 - accuracy: 0.6588 - cosine_proximity: 1.0000 - val_loss: 16.9370 - val_accuracy: 0.9734 - val_cosine_proximity: 1.0000\n",
      "Epoch 30/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 10.3066 - accuracy: 0.6391 - cosine_proximity: 1.0000 - val_loss: 13.8512 - val_accuracy: 0.1844 - val_cosine_proximity: 1.0000\n",
      "Epoch 31/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 11.2410 - accuracy: 0.5356 - cosine_proximity: 1.0000 - val_loss: 34.3825 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9999\n",
      "Epoch 32/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 13.2892 - accuracy: 0.5544 - cosine_proximity: 0.9999 - val_loss: 21.6363 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 1.0000\n",
      "Epoch 33/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 9.6861 - accuracy: 0.5944 - cosine_proximity: 1.0000 - val_loss: 13.7097 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9999\n",
      "Epoch 34/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 9.7762 - accuracy: 0.6069 - cosine_proximity: 0.9999 - val_loss: 18.3227 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9999\n",
      "Epoch 35/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 7.6543 - accuracy: 0.6730 - cosine_proximity: 1.0000 - val_loss: 12.9266 - val_accuracy: 0.9385 - val_cosine_proximity: 1.0000\n",
      "Epoch 36/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 8.7767 - accuracy: 0.5978 - cosine_proximity: 1.0000 - val_loss: 21.1008 - val_accuracy: 0.0000e+00 - val_cosine_proximity: 0.9999\n",
      "Epoch 37/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 8.9212 - accuracy: 0.6063 - cosine_proximity: 1.0000 - val_loss: 10.3972 - val_accuracy: 0.4939 - val_cosine_proximity: 1.0000\n",
      "Epoch 38/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 8.7713 - accuracy: 0.7377 - cosine_proximity: 1.0000 - val_loss: 21.0351 - val_accuracy: 0.0082 - val_cosine_proximity: 0.9999\n",
      "Epoch 39/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 7.9783 - accuracy: 0.6896 - cosine_proximity: 1.0000 - val_loss: 74.3193 - val_accuracy: 0.9918 - val_cosine_proximity: 1.0000\n",
      "Epoch 40/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 6.3877 - accuracy: 0.7272 - cosine_proximity: 1.0000 - val_loss: 12.0608 - val_accuracy: 0.0082 - val_cosine_proximity: 1.0000\n",
      "Epoch 41/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 5.3600 - accuracy: 0.7417 - cosine_proximity: 1.0000 - val_loss: 15.2349 - val_accuracy: 0.0143 - val_cosine_proximity: 1.0000\n",
      "Epoch 42/64\n",
      "176/176 [==============================] - 1s 9ms/step - loss: 5.8477 - accuracy: 0.8355 - cosine_proximity: 1.0000 - val_loss: 13.4856 - val_accuracy: 0.9877 - val_cosine_proximity: 1.0000\n",
      "Epoch 43/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 6.7892 - accuracy: 0.7366 - cosine_proximity: 1.0000 - val_loss: 6.1439 - val_accuracy: 0.9836 - val_cosine_proximity: 1.0000\n",
      "Epoch 44/64\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 244443343717853.4688 - accuracy: 0.3957 - cosine_proximity: 0.8458 - val_loss: 31.0428 - val_accuracy: 0.1475 - val_cosine_proximity: 1.0000\n",
      "Epoch 45/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 13.0095 - accuracy: 0.5658 - cosine_proximity: 1.0000 - val_loss: 19.3752 - val_accuracy: 0.2664 - val_cosine_proximity: 1.0000\n",
      "Epoch 46/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 12.5897 - accuracy: 0.5807 - cosine_proximity: 1.0000 - val_loss: 19.2953 - val_accuracy: 0.4529 - val_cosine_proximity: 1.0000\n",
      "Epoch 47/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 13.2599 - accuracy: 0.5810 - cosine_proximity: 1.0000 - val_loss: 22.8588 - val_accuracy: 0.2398 - val_cosine_proximity: 1.0000\n",
      "Epoch 48/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 14.3430 - accuracy: 0.5570 - cosine_proximity: 1.0000 - val_loss: 128.8693 - val_accuracy: 0.4201 - val_cosine_proximity: 1.0000\n",
      "Epoch 49/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 12.1757 - accuracy: 0.5864 - cosine_proximity: 1.0000 - val_loss: 44.6106 - val_accuracy: 0.7418 - val_cosine_proximity: 1.0000\n",
      "Epoch 50/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 12.3576 - accuracy: 0.5929 - cosine_proximity: 1.0000 - val_loss: 20.8288 - val_accuracy: 0.1557 - val_cosine_proximity: 0.9999\n",
      "Epoch 51/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 16.1674 - accuracy: 0.5331 - cosine_proximity: 1.0000 - val_loss: 20.5389 - val_accuracy: 0.3053 - val_cosine_proximity: 1.0000\n",
      "Epoch 52/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 14.8777 - accuracy: 0.5191 - cosine_proximity: 1.0000 - val_loss: 17.6608 - val_accuracy: 0.2131 - val_cosine_proximity: 1.0000\n",
      "Epoch 53/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 15.6914 - accuracy: 0.5211 - cosine_proximity: 1.0000 - val_loss: 33.3302 - val_accuracy: 0.5266 - val_cosine_proximity: 1.0000\n",
      "Epoch 54/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 12.6425 - accuracy: 0.5200 - cosine_proximity: 1.0000 - val_loss: 32.2290 - val_accuracy: 0.5861 - val_cosine_proximity: 1.0000\n",
      "Epoch 55/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 15.3443 - accuracy: 0.5559 - cosine_proximity: 1.0000 - val_loss: 32.1764 - val_accuracy: 0.2275 - val_cosine_proximity: 1.0000\n",
      "Epoch 56/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 13.9033 - accuracy: 0.5373 - cosine_proximity: 1.0000 - val_loss: 18.4650 - val_accuracy: 0.0943 - val_cosine_proximity: 0.9999\n",
      "Epoch 57/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 17.5574 - accuracy: 0.5755 - cosine_proximity: 1.0000 - val_loss: 15.5311 - val_accuracy: 0.1004 - val_cosine_proximity: 1.0000\n",
      "Epoch 58/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 18.1129 - accuracy: 0.5162 - cosine_proximity: 1.0000 - val_loss: 15.8494 - val_accuracy: 0.3402 - val_cosine_proximity: 1.0000\n",
      "Epoch 59/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 18.6597 - accuracy: 0.5043 - cosine_proximity: 1.0000 - val_loss: 29.9284 - val_accuracy: 0.1025 - val_cosine_proximity: 1.0000\n",
      "Epoch 60/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 14.4456 - accuracy: 0.5237 - cosine_proximity: 1.0000 - val_loss: 23.9404 - val_accuracy: 0.2561 - val_cosine_proximity: 1.0000\n",
      "Epoch 61/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 16.8377 - accuracy: 0.5630 - cosine_proximity: 1.0000 - val_loss: 24.1555 - val_accuracy: 0.2869 - val_cosine_proximity: 1.0000\n",
      "Epoch 62/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 20.6008 - accuracy: 0.5294 - cosine_proximity: 1.0000 - val_loss: 16.4329 - val_accuracy: 0.5287 - val_cosine_proximity: 1.0000\n",
      "Epoch 63/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 20.3470 - accuracy: 0.5037 - cosine_proximity: 1.0000 - val_loss: 343.6198 - val_accuracy: 0.9918 - val_cosine_proximity: 0.9999\n",
      "Epoch 64/64\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 24.6888 - accuracy: 0.5476 - cosine_proximity: 1.0000 - val_loss: 250.3241 - val_accuracy: 0.7152 - val_cosine_proximity: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe65eda3b70>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back = 15\n",
    "num_epochs = 64\n",
    "\n",
    "train_generator = keras.preprocessing.sequence.TimeseriesGenerator(close_train, close_train, length=look_back, batch_size=20)   \n",
    "val_generator = keras.preprocessing.sequence.TimeseriesGenerator(close_val, close_val, length=look_back, batch_size=10)     \n",
    "test_generator = keras.preprocessing.sequence.TimeseriesGenerator(close_test, close_test, length=look_back, batch_size=1)\n",
    "\n",
    "\n",
    "def customloss():\n",
    "    def loss(y_true, y_pred):\n",
    "        # Use x here as you wish\n",
    "        err = keras.backend.mean(keras.backend.square(y_pred[3:] - y_true[3:]), axis=-1)\n",
    "        return err\n",
    "\n",
    "    return loss\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.LSTM(256,\n",
    "                      activation=\"relu\",\n",
    "                    #recurrent_activation=\"sigmoid\",\n",
    "                      use_bias=True,\n",
    "                      input_shape=(look_back, 4)),\n",
    "    keras.layers.Dense(4),\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=customloss(), metrics=[\"accuracy\", \"cosine_proximity\"])\n",
    "\n",
    "\n",
    "model.fit(train_generator, epochs=num_epochs, verbose=1, validation_data=val_generator, steps_per_epoch=len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7437268045486938\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_generator)\n",
    "\n",
    "close_train_1 = close_train[0:, 3:].reshape((-1))\n",
    "close_val_1 = close_val[0:, 3:].reshape((-1))\n",
    "close_test_1 = close_test[0:, 3:].reshape((-1))\n",
    "prediction_1 = prediction[0:, 3:].reshape((-1))\n",
    "\n",
    "diff = close_test_1[look_back:] - prediction_1\n",
    "avg_diff = np.mean(diff)\n",
    "print(avg_diff)\n",
    "\n",
    "def predict(num_prediction, before_lookback, model):\n",
    "    if (before_lookback > 0):\n",
    "        prediction_list = close_data[-look_back - before_lookback:-before_lookback]\n",
    "    else:\n",
    "        prediction_list = close_data[-look_back:]\n",
    "    for _ in range(num_prediction):\n",
    "        x = prediction_list[-look_back:]\n",
    "#         print(\"Pred list\", prediction_list)\n",
    "        x = x.reshape((1, look_back, 4))\n",
    "        out = model.predict(x)\n",
    "#         print(\"Out\", out)\n",
    "        prediction_list = np.append(prediction_list, out, axis=0)\n",
    "    prediction_list = prediction_list[look_back:]\n",
    "        \n",
    "    return prediction_list\n",
    "    \n",
    "def predict_dates(num_prediction, before_lookback):\n",
    "    last_date = stonks.timestamp.values[-1 - before_lookback]\n",
    "    prediction_dates = pd.date_range(last_date, periods=num_prediction+1+before_lookback).tolist()\n",
    "    return prediction_dates\n",
    "\n",
    "num_prediction = 4\n",
    "before_lookback = 0\n",
    "forecast = predict(num_prediction, before_lookback, model)[0:, 3:].reshape((-1))\n",
    "forecast_dates = predict_dates(num_prediction, before_lookback)\n",
    "prediction_1 = np.concatenate([[None] * look_back, prediction_1 + avg_diff])\n",
    "trace1 = go.Scatter(\n",
    "    x = np.concatenate([date_train, date_val]),\n",
    "    y = np.concatenate([close_train_1, close_val_1]),\n",
    "    mode = 'lines',\n",
    "    name = 'Real Data - trained'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = date_test,\n",
    "    y = prediction_1,\n",
    "    mode = 'lines',\n",
    "    name = 'Prediction'\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x = date_test,\n",
    "    y = close_test_1,\n",
    "    mode='lines',\n",
    "    name = 'Real Data - untrained'\n",
    ")\n",
    "forecast = go.Scatter(\n",
    "    x = forecast_dates,\n",
    "    y = forecast + avg_diff,\n",
    "    mode = 'lines+markers+text',\n",
    "    texttemplate = \"%{y:.2f}\",\n",
    "    name = 'Forecast'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = \"Google Stock\",\n",
    "    xaxis = {'title' : \"Date\"},\n",
    "    yaxis = {'title' : \"Close\"}\n",
    ")\n",
    "fig = go.Figure(data=[trace1, trace2, trace3, forecast], layout=layout)\n",
    "fig.show(renderer=\"browser\")\n",
    "# py.plot(fig, filename = 'basic-line', renderer=\"browser\", auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_html(fig, file='tracing_pred.html', auto_open=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('good_model_bak_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"good_model_bak_2.h5\", custom_objects={'loss': customloss()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
